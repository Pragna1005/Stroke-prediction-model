{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anuranjani/Desktop/my_projects/stroke-prediction-model/stroke-prediction-project/src/data_processing\n",
      "2025-04-13 01:45:04 - INFO: Loading dataset from /Users/anuranjani/Desktop/my_projects/stroke-prediction-model/stroke-prediction-project/data/raw/healthcare-dataset-stroke-data.csv\n",
      "2025-04-13 01:45:04 - INFO: Dataset shape: (5110, 12)\n",
      "2025-04-13 01:45:04 - INFO: Missing values:\n",
      "id                     0\n",
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "ever_married           0\n",
      "work_type              0\n",
      "Residence_type         0\n",
      "avg_glucose_level      0\n",
      "bmi                  201\n",
      "smoking_status         0\n",
      "stroke                 0\n",
      "dtype: int64\n",
      "2025-04-13 01:45:04 - INFO: Processed data saved at /Users/anuranjani/Desktop/my_projects/stroke-prediction-model/stroke-prediction-project/data/processed/cleaned_dataset.csv\n",
      "2025-04-13 01:45:04 - INFO: Processed dataset shape: (5110, 16)\n",
      "2025-04-13 01:45:04 - INFO: Feature statistics saved at /Users/anuranjani/Desktop/my_projects/stroke-prediction-model/stroke-prediction-project/data/processed/feature_statistics.txt\n",
      "\n",
      "Processed Data Overview:\n",
      "   gender       age  ...  age_bmi_interaction  hypertension_heart_disease\n",
      "0       1  1.051434  ...               2452.2                           0\n",
      "1       0  0.786070  ...               1714.1                           0\n",
      "2       1  1.626390  ...               2600.0                           0\n",
      "3       0  0.255342  ...               1685.6                           0\n",
      "4       0  1.582163  ...               1896.0                           0\n",
      "\n",
      "[5 rows x 16 columns]\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 16 columns):\n",
      " #   Column                      Non-Null Count  Dtype   \n",
      "---  ------                      --------------  -----   \n",
      " 0   gender                      5110 non-null   int64   \n",
      " 1   age                         5110 non-null   float64 \n",
      " 2   hypertension                5110 non-null   int64   \n",
      " 3   heart_disease               5110 non-null   int64   \n",
      " 4   ever_married                5110 non-null   int64   \n",
      " 5   work_type                   5110 non-null   int64   \n",
      " 6   Residence_type              5110 non-null   int64   \n",
      " 7   avg_glucose_level           5110 non-null   float64 \n",
      " 8   bmi                         5110 non-null   float64 \n",
      " 9   smoking_status              5110 non-null   int64   \n",
      " 10  stroke                      5110 non-null   int64   \n",
      " 11  age_group                   5110 non-null   category\n",
      " 12  bmi_category                5110 non-null   category\n",
      " 13  glucose_category            5110 non-null   category\n",
      " 14  age_bmi_interaction         5110 non-null   float64 \n",
      " 15  hypertension_heart_disease  5110 non-null   int64   \n",
      "dtypes: category(3), float64(4), int64(9)\n",
      "memory usage: 534.7 KB\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/anuranjani/Desktop/my_projects/stroke-prediction-model/stroke-prediction-project/src/data_processing\n",
    "!python cleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# For the data scaling and encoding of the categorical features in dataset:\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "DATA_PATH = os.path.join(BASE_DIR, 'data', 'processed', 'cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0: 3403, 1: 174})\n",
      "After SMOTE : Counter({0: 3403, 1: 3403})\n",
      "Test Set    : Counter({0: 1458, 1: 75})\n"
     ]
    }
   ],
   "source": [
    "# 2. Separate features and target\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "# 3. Split into train/test before any preprocessing!\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# 5. Fit encoders on training data only\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train_cat = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_test_cat = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# 6. Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test_num = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# 7. Combine processed categorical + numerical features\n",
    "import numpy as np\n",
    "X_train_processed = np.hstack((X_train_num, X_train_cat))\n",
    "X_test_processed = np.hstack((X_test_num, X_test_cat))\n",
    "\n",
    "# 8. Apply SMOTE only on the training data\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "# 9. Print the class distributions\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "print(\"After SMOTE :\", Counter(y_train_resampled))\n",
    "print(\"Test Set    :\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the processed data after SMOTE to CSV\n",
    "X_train_resampled_df = pd.DataFrame(X_train_resampled)\n",
    "y_train_resampled_df = pd.DataFrame(y_train_resampled)\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed)\n",
    "X_train_resampled_df.to_csv(os.path.join(BASE_DIR, 'data', 'processed', 'X_train_resampled.csv'), index=False)\n",
    "y_train_resampled_df.to_csv(os.path.join(BASE_DIR, 'data', 'processed', 'y_train_resampled.csv'), index=False)\n",
    "X_test_processed_df.to_csv(os.path.join(BASE_DIR, 'data', 'processed', 'X_test_processed.csv'), index=False)\n",
    "y_test.to_csv(os.path.join(BASE_DIR, 'data', 'processed', 'y_test.csv'), index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
